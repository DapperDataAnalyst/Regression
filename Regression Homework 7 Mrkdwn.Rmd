---
title: "Regression Homework 7"
output: html_document
date: "2023-03-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
data = read.csv('HW7_data.csv')

# Problem 1.1 & 1.2
y = unlist(data[1])
x = unlist(data[2])
n = nrow(data)
sigma_sqr = var(y)
t = 5

for (k in 2:100)
{
  first_deriv = sum((y-exp(t*x))*(-x*exp(t*x)))
  second_deriv = sum(-x^2*y*exp(t*x) + 2*x^2*exp(2*t*x))
  t = t - first_deriv/second_deriv
}

y_hat = exp(t*x)
e_hat = y - y_hat


# Problem 1.3
for(kk in 1:1000)
{
  q = c(1:n)
  qq = sample(q,replace=TRUE)
  xx = x[qq]
  yy = y[qq]
  yyy = exp(t+x) + sigma_sqr*rnorm(n)
}

```

## Problem 1.1
We are given that $y_i = exp(\theta x_i) + \sigma\epsilon_i$. Given this equation, we know that our likelihood function is $I(\theta) = \frac{1}{2} \sum(y_i - exp(\theta x_i)^2$.

The first derivative of the likelihood function with respect to theta is $$I'(\theta) = \sum(y_i - exp(\theta x_i))(-x_i exp(\theta x_i)) = \sum(-x_iy_iexp(\theta x_i) + x_iexp(2\theta x_i))$$.

The second derivative of the likelihood function with respect to theta is $I''(\theta) = \sum(-x_i^2y_iexp(\theta x_i) + 2x_i^2exp(2\theta x_i))$.

We use the formula $\theta(t + 1) = \theta(t) - \frac{I'(\theta(t))}{I''(\theta(t))}$ and running this through 99 iterations yields us the estimate for $\hat{\theta}$.

## Problem 1.2
Using the method described in Problem 1.1, the estimated value of $\hat{\theta} =$ `r t`





